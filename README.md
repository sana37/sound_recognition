# sound_recognition

CNNを使った音声認識ができます。


## 概要

wav形式音声データをフーリエ変換して得られた周波数データをCNNに学習させます。

ここで実装したCNNは、入力がtrueかfalseか判定するだけの二値分類器です。

学習させたCNNを実際に使って音声デバイスからの音を判別させることもできます。


## 詳細

CNNの構築にはtensorflowを使っています。

また、wavファイルから読み取った音声データは、`scipy.fftpack`を使ってフーリエ変換しています。




### wavファイル、音声デバイスの設定

 * rate : 48000 Hz

 * format : signed int 16 bits little endian

 * channel : monaural


### 使用したバージョン

 * `python 3.5.2`

 * `tensorflow 1.2.1`


## 使用例

指ぱっちんの音を学習させて実際に使ってみました。

https://www.youtube.com/watch?v=zfpo7Ow4mkc


## 使い方

### データセット

データセットが格納されているディレクトリを`wavdataset.py`に教えてあげます。

具体的には、`wavdataset.py`の`DatasetManager.true_dir_list`には正解データが入っているディレクトリのパスを、
`false_dir_list`には不正解データが入っているディレクトリのパスを、それぞれ追加します。

`wavdataset.py`はデータセットを管理するモジュールです。

`wavdataset.py`は、指定されたディレクトリからwav形式の音声ファイルを読み込んでフーリエ変換し、
変換後のデータを集め、これをデータセットとして、他のモジュールに提供します。



### 学習

データセットを使って学習させたいときはpythonインタプリタで`training.py`を実行します。

`training.py`は、所定のパスにあるデータセットを使ってCNNに学習させます。

学習が終わると、得られたパラメータを保存します。

学習パラメータは`sound_recognition_model.なんたら`みたいなファイルとかに保存されます。

また、`training.py`では学習後の挙動の確認用として、各入力データに対する結果をいくつか表示するようになっています。



### 音声デバイスを使った動作確認

`realtime.py`は、音声デバイスから取得した音声をCNNに与えて、実際に正しく判定できるかどうか確認するためのモジュールです。

どの音声デバイスを使用するのか指定する必要があり、`realtime.py`ではデバイス名でデバイスを見つけ、指定しています。

使用したい音声デバイスによってデバイス名は異なるので、`realtime.py`では変数`DEVICE_NAME`にて使いたいデバイスの名前を設定しています。

CNNのパラメータは、`training.py`で学習したときに保存されたものを読み込んで使っています。
