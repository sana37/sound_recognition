# sound_recognition

tensorflowでcnnを使って音声認識をするものをつくりました。

入力がtrueかfalseか判定するだけの二値分類器です。


### 使用したバージョン

`python 3.5.2`
`tensorflow 1.2.1`


## 使い方

### データセット

データセットが格納されているディレクトリを`wavdataset.py`に教えてあげます。

具体的には、`wavdataset.py`の`DatasetManager.true_dir_list`には正解データが入っているディレクトリのパスを、
`false_dir_list`には不正解データが入っているディレクトリのパスを、それぞれ追加します。

`wavdataset.py`はデータセットを管理するモジュールです。

pythonインタプリタによって直接実行されることはありません。

指定されたディレクトリからwav形式の音声ファイルを読み込み、`scipy.fftpack`を使ってこれをフーリエ変換します。

フーリエ変換すると、横軸が時間、縦軸が周波数、輝度が振幅となる画像のようなものができます。

`wavdataset.py`は、この画像を集めてデータセットとし、他のモジュールにデータセットを提供します。



### 学習

データセットを使って学習させたいときはpythonインタプリタで`training.py`を実行します。

`training.py`はデータセットを取得し、これを教師データとしてcnnに与えて特徴を学習させます。

学習が終わると、得られたパラメータを保存します。

学習パラメータは`sound_recognition_model.なんたら`みたいなファイルとかに保存されます。

また、`training.py`では学習後の挙動の確認用として、各入力画像に対する結果をいくつか表示するようになっています。



### マイクを使った動作確認

マイクから取得した音声を、学習済みcnnに与えて、実際に正しく判定できるかどうか確認します。

この機能を提供するのが、realtime.pyです。
